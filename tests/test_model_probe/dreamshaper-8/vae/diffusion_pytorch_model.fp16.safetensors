{
    "decoder.conv_in.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.conv_in.weight": {
        "shape": [
            512,
            4,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.conv_norm_out.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.conv_norm_out.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.conv_out.bias": {
        "shape": [
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.conv_out.weight": {
        "shape": [
            3,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.group_norm.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.group_norm.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.to_k.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.to_k.weight": {
        "shape": [
            512,
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.to_out.0.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.to_out.0.weight": {
        "shape": [
            512,
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.to_q.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.to_q.weight": {
        "shape": [
            512,
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.to_v.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.attentions.0.to_v.weight": {
        "shape": [
            512,
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.0.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.0.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.0.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.0.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.0.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.0.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.0.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.0.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.1.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.1.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.1.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.1.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.1.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.1.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.1.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.mid_block.resnets.1.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.0.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.0.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.0.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.0.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.0.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.0.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.0.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.0.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.1.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.1.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.1.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.1.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.1.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.1.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.1.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.1.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.2.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.2.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.2.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.2.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.2.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.2.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.2.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.resnets.2.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.upsamplers.0.conv.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.0.upsamplers.0.conv.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.0.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.0.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.0.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.0.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.0.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.0.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.0.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.0.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.1.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.1.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.1.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.1.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.1.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.1.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.1.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.1.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.2.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.2.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.2.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.2.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.2.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.2.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.2.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.resnets.2.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.upsamplers.0.conv.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.1.upsamplers.0.conv.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.conv1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.conv1.weight": {
        "shape": [
            256,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.conv2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.conv2.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.conv_shortcut.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.conv_shortcut.weight": {
        "shape": [
            256,
            512,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.norm2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.0.norm2.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.1.conv1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.1.conv1.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.1.conv2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.1.conv2.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.1.norm1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.1.norm1.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.1.norm2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.1.norm2.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.2.conv1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.2.conv1.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.2.conv2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.2.conv2.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.2.norm1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.2.norm1.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.2.norm2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.resnets.2.norm2.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.upsamplers.0.conv.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.2.upsamplers.0.conv.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.conv1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.conv1.weight": {
        "shape": [
            128,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.conv2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.conv2.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.conv_shortcut.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.conv_shortcut.weight": {
        "shape": [
            128,
            256,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.norm1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.norm1.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.norm2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.0.norm2.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.1.conv1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.1.conv1.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.1.conv2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.1.conv2.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.1.norm1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.1.norm1.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.1.norm2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.1.norm2.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.2.conv1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.2.conv1.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.2.conv2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.2.conv2.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.2.norm1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.2.norm1.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.2.norm2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "decoder.up_blocks.3.resnets.2.norm2.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.conv_in.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.conv_in.weight": {
        "shape": [
            128,
            3,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.conv_norm_out.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.conv_norm_out.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.conv_out.bias": {
        "shape": [
            8
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.conv_out.weight": {
        "shape": [
            8,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.downsamplers.0.conv.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.downsamplers.0.conv.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.0.conv1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.0.conv1.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.0.conv2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.0.conv2.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.0.norm1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.0.norm1.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.0.norm2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.0.norm2.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.1.conv1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.1.conv1.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.1.conv2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.1.conv2.weight": {
        "shape": [
            128,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.1.norm1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.1.norm1.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.1.norm2.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.0.resnets.1.norm2.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.downsamplers.0.conv.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.downsamplers.0.conv.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.conv1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.conv1.weight": {
        "shape": [
            256,
            128,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.conv2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.conv2.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.conv_shortcut.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.conv_shortcut.weight": {
        "shape": [
            256,
            128,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.norm1.bias": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.norm1.weight": {
        "shape": [
            128
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.norm2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.0.norm2.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.1.conv1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.1.conv1.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.1.conv2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.1.conv2.weight": {
        "shape": [
            256,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.1.norm1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.1.norm1.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.1.norm2.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.1.resnets.1.norm2.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.downsamplers.0.conv.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.downsamplers.0.conv.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.conv1.weight": {
        "shape": [
            512,
            256,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.conv_shortcut.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.conv_shortcut.weight": {
        "shape": [
            512,
            256,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.norm1.bias": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.norm1.weight": {
        "shape": [
            256
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.0.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.1.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.1.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.1.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.1.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.1.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.1.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.1.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.2.resnets.1.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.0.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.0.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.0.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.0.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.0.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.0.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.0.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.0.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.1.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.1.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.1.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.1.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.1.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.1.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.1.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.down_blocks.3.resnets.1.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.group_norm.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.group_norm.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.to_k.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.to_k.weight": {
        "shape": [
            512,
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.to_out.0.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.to_out.0.weight": {
        "shape": [
            512,
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.to_q.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.to_q.weight": {
        "shape": [
            512,
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.to_v.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.attentions.0.to_v.weight": {
        "shape": [
            512,
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.0.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.0.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.0.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.0.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.0.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.0.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.0.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.0.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.1.conv1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.1.conv1.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.1.conv2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.1.conv2.weight": {
        "shape": [
            512,
            512,
            3,
            3
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.1.norm1.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.1.norm1.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.1.norm2.bias": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "encoder.mid_block.resnets.1.norm2.weight": {
        "shape": [
            512
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "post_quant_conv.bias": {
        "shape": [
            4
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "post_quant_conv.weight": {
        "shape": [
            4,
            4,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "quant_conv.bias": {
        "shape": [
            8
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    },
    "quant_conv.weight": {
        "shape": [
            8,
            8,
            1,
            1
        ],
        "dtype": "torch.float16",
        "fakeTensor": true
    }
}